{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'upscalar(ESRGAN)'\n",
      "c:\\Users\\alapa\\imageupscaler\\upscalar(ESRGAN)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alapa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\magics\\osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "%cd upscalar(ESRGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder structure set up successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory paths\n",
    "model_dir = 'weights'\n",
    "input_dir = 'input'\n",
    "results_dir = 'results'\n",
    "\n",
    "# Ensure main directories exist\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Create a subdirectory in `results` for each model\n",
    "for model_file in os.listdir(model_dir):\n",
    "    if model_file.endswith('.pth'):\n",
    "        model_results_dir = os.path.join(results_dir, model_file)\n",
    "        os.makedirs(model_results_dir, exist_ok=True)\n",
    "\n",
    "print(\"Folder structure set up successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload image\n",
      "Image uploaded and saved to: input\\264286_00007889.jpg\n"
     ]
    }
   ],
   "source": [
    "import tkinter\n",
    "from tkinter import filedialog\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Set the path to your input folder\n",
    "input_folder = \"input\"  # Name of the folder where the image will be saved\n",
    "\n",
    "# Create a Tkinter window\n",
    "root = tkinter.Tk()\n",
    "\n",
    "\n",
    "print(\"Upload image\")\n",
    "\n",
    "# Prompt the user to select an image file\n",
    "file_path = filedialog.askopenfilename(\n",
    "    filetypes=[(\"Image files\", \"*.jpg;*.jpeg;*.png;*.gif;*.bmp\")]\n",
    ")\n",
    "\n",
    "if not file_path:\n",
    "    print(\"No file selected. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "root.withdraw()  # Hide the main window\n",
    "\n",
    "# Load the selected image\n",
    "img = Image.open(file_path)\n",
    "\n",
    "# Ensure the 'input' folder exists, create it if it doesn't\n",
    "os.makedirs(input_folder, exist_ok=True)\n",
    "\n",
    "# Save the image in the input folder with the same name\n",
    "image_name = os.path.basename(file_path)  # Extract the file name from the selected file path\n",
    "saved_image_path = os.path.join(input_folder, image_name)  # Path where the image will be saved\n",
    "\n",
    "# Save the image to the 'input' folder\n",
    "img.save(saved_image_path)\n",
    "print(f\"Image uploaded and saved to: {saved_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RealESRGAN_x2.pth\n",
      "RealESRGAN_x2plus.pth\n",
      "RealESRGAN_x4.pth\n",
      "RealESRGAN_x4plus.pth\n",
      "RealESRGAN_x8.pth\n",
      "RealESRNet_x4plus.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from os.path import join, basename\n",
    "from PIL import Image\n",
    "from py_real_esrgan.model import RealESRGAN\n",
    "\n",
    "\n",
    "# Directory where models are stored\n",
    "model_dir = \"weights\"\n",
    "\n",
    "# Device selection (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load Real-ESRGAN models for each model file in the models directory\n",
    "for model_file in os.listdir(model_dir):\n",
    "    print(model_file)\n",
    "    if model_file.endswith('.pth'):\n",
    "        model_path = os.path.join(model_dir, model_file)\n",
    "        result_path = os.path.join(results_dir,model_file)\n",
    "        # Infer scale from the model filename (2x, 4x, 8x)\n",
    "        if 'x2' in model_file:\n",
    "            model_scale = 2\n",
    "        elif 'x4' in model_file:\n",
    "            model_scale = 4\n",
    "        elif 'x8' in model_file:\n",
    "            model_scale = 8\n",
    "        else:\n",
    "            exit()  # Default scale if not specified in the filename\n",
    "\n",
    "        model = RealESRGAN(device, scale=model_scale)\n",
    "        model.load_weights( model_path , download=True )\n",
    "        \n",
    "        path_to_image = saved_image_path\n",
    "        image = Image.open(path_to_image).convert('RGB')\n",
    "\n",
    "        sr_image = model.predict(image)\n",
    "        output_path = join(result_path , f\"output__{basename(file_path)}\")\n",
    "        sr_image.save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# live video processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd upscalar(ESRGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from os.path import join, basename\n",
    "from PIL import Image\n",
    "from py_real_esrgan.model import RealESRGAN\n",
    "\n",
    "# Directory where models are stored\n",
    "model_dir = \"weights\"\n",
    "\n",
    "# Device selection (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_scale = 4 # 2 or 4 or 8\n",
    "model_path = 'weights/RealESRNet_x4plus.pth'\n",
    "\n",
    "model = RealESRGAN(device, scale=model_scale)\n",
    "model.load_weights( model_path , download=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch  # Assuming the model is a PyTorch model\n",
    "\n",
    "# Step 1: Capture live video and save frames to `original_temp_frames`\n",
    "def capture_live_feed(original_frames_folder, fps=30):\n",
    "    # Set up video capture for live feed (0 for the default camera)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open the camera.\")\n",
    "        return\n",
    "    \n",
    "    frame_count = 0\n",
    "    print(\"Capturing live feed... Press 'q' to quit.\")\n",
    "    \n",
    "    # Capture loop\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Display the live feed\n",
    "        cv2.imshow('Live Feed', frame)\n",
    "        \n",
    "        # Save each frame temporarily\n",
    "        frame_count += 1\n",
    "        frame_path = os.path.join(original_frames_folder, f\"frame_{frame_count}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        \n",
    "        # Quit with 'q' key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        # Wait to match the target FPS\n",
    "        cv2.waitKey(int(1000 / fps))\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Captured live feed frames saved to {original_frames_folder}\")\n",
    "\n",
    "# Step 2: Enhance saved frames and create reconstructed video\n",
    "def enhance_and_reconstruct(original_frames_folder, enhanced_frames_folder, reconstructed_video_path, model, fps=30):\n",
    "    # Set up video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    \n",
    "    # Loop through saved frames\n",
    "    frame_count = 1\n",
    "    video_writer = None\n",
    "    \n",
    "    print(\"Starting enhancement and reconstruction...\")\n",
    "    while True:\n",
    "        # Path of the current frame to be enhanced\n",
    "        frame_path = os.path.join(original_frames_folder, f\"frame_{frame_count}.jpg\")\n",
    "        \n",
    "        # Check if the frame exists\n",
    "        if not os.path.exists(frame_path):\n",
    "            break\n",
    "        \n",
    "        # Load the frame, enhance it, and save to enhanced folder\n",
    "        frame_pil = Image.open(frame_path).convert('RGB')\n",
    "        sr_image = model.predict(frame_pil)  # Enhance with the model\n",
    "        enhanced_frame = np.array(sr_image)\n",
    "        \n",
    "        # Save enhanced frame\n",
    "        enhanced_frame_path = os.path.join(enhanced_frames_folder, f\"frame_{frame_count}.jpg\")\n",
    "        sr_image.save(enhanced_frame_path)\n",
    "        \n",
    "        # Initialize video writer if not already set up\n",
    "        if video_writer is None:\n",
    "            height, width = enhanced_frame.shape[:2]\n",
    "            video_writer = cv2.VideoWriter(reconstructed_video_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        # Write enhanced frame to output video\n",
    "        video_writer.write(cv2.cvtColor(enhanced_frame, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        frame_count += 1\n",
    "\n",
    "    # Release resources when done\n",
    "    video_writer.release()\n",
    "    print(f\"Enhanced frames and reconstructed video saved to {enhanced_frames_folder} and {reconstructed_video_path}\")\n",
    "\n",
    "# Set up directories\n",
    "original_frames_folder = \"temp\"      # Temporary folder for original frames\n",
    "enhanced_frames_folder = \"temp_enhanced\"      # Temporary folder for enhanced frames\n",
    "reconstructed_video_path = \"output/reconstructed_video.mp4\"  # Path to save the output video\n",
    "\n",
    "# Create folders if they don't exist\n",
    "os.makedirs(original_frames_folder, exist_ok=True)\n",
    "os.makedirs(enhanced_frames_folder, exist_ok=True)\n",
    "\n",
    "# Run the capture and enhancement processes in sequence\n",
    "capture_live_feed(original_frames_folder)\n",
    "enhance_and_reconstruct(original_frames_folder, enhanced_frames_folder, reconstructed_video_path, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhance_and_reconstruct(original_frames_folder, enhanced_frames_folder, reconstructed_video_path, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# below are test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## V1\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def process_live_feed(output_frames_folder, reconstructed_video_path, fps=30):\n",
    "    # Set up directories\n",
    "    os.makedirs(output_frames_folder, exist_ok=True)\n",
    "    frame_count = 0\n",
    "    \n",
    "    # Set up video capture for live feed (0 for the default camera)\n",
    "    cap = cv2.VideoCapture(0)  \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open the camera.\")\n",
    "        return\n",
    "    \n",
    "    # Get the width and height of the frames\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Set up video writer for real-time reconstructed video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    video_writer = cv2.VideoWriter(reconstructed_video_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    print(\"Processing live feed... Press 'q' to quit.\")\n",
    "    \n",
    "    # Real-time frame processing loop\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Save each frame temporarily\n",
    "        frame_count += 1\n",
    "        frame_path = os.path.join(output_frames_folder, f\"frame_{frame_count}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        \n",
    "        # Write each frame to the output video\n",
    "        video_writer.write(frame)\n",
    "        \n",
    "        # Remove the frame file immediately after writing to video\n",
    "        os.remove(frame_path)\n",
    "        \n",
    "        # Display the live feed\n",
    "        cv2.imshow('Live Feed', frame)\n",
    "        \n",
    "        # Quit with 'q' key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Reconstructed video saved to {reconstructed_video_path}\")\n",
    "\n",
    "# Example usage\n",
    "output_frames_folder = \"temp\"  # Temporary folder for frames\n",
    "reconstructed_video_path = \"output/reconstructed_video.mp4\"  # Save path for the output videoq\n",
    "process_live_feed(output_frames_folder, reconstructed_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## V2\n",
    "\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch  # Assuming the model is a PyTorch model\n",
    "\n",
    "def process_live_feed_with_enhancement(output_frames_folder, reconstructed_video_path, model, fps=30):\n",
    "    # Set up directories\n",
    "    os.makedirs(output_frames_folder, exist_ok=True)\n",
    "    frame_count = 0\n",
    "    \n",
    "    # Set up video capture for live feed (0 for the default camera)\n",
    "    cap = cv2.VideoCapture(0)  \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open the camera.\")\n",
    "        return\n",
    "    \n",
    "    # Get the width and height of the frames\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Set up video writer for the reconstructed video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    video_writer = cv2.VideoWriter(reconstructed_video_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    print(\"Processing live feed... Press 'q' to quit.\")\n",
    "    \n",
    "    # Real-time frame processing loop\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Display the live feed (original frame)\n",
    "        cv2.imshow('Live Feed', frame)\n",
    "        \n",
    "        # Convert frame to a PIL image for model processing\n",
    "        frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Enhance frame using the provided model\n",
    "        sr_image = model.predict(frame_pil)  # Model enhancement\n",
    "\n",
    "        # Convert enhanced image back to OpenCV format\n",
    "        enhanced_frame = cv2.cvtColor(np.array(sr_image), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Save each enhanced frame temporarily\n",
    "        frame_count += 1\n",
    "        frame_path = os.path.join(output_frames_folder, f\"frame_{frame_count}.jpg\")\n",
    "        cv2.imwrite(frame_path, enhanced_frame)\n",
    "        \n",
    "        # Write each enhanced frame to the output video\n",
    "        video_writer.write(enhanced_frame)\n",
    "        \n",
    "        # Remove the enhanced frame file immediately after writing to video\n",
    "        #os.remove(frame_path)\n",
    "        \n",
    "        # Quit with 'q' key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Reconstructed video saved to {reconstructed_video_path}\")\n",
    "\n",
    "# Example usage\n",
    "output_frames_folder = \"temp\"  # Temporary folder for frames\n",
    "reconstructed_video_path = \"output/reconstructed_video.mp4\"  # Save path for the output video\n",
    "process_live_feed_with_enhancement(output_frames_folder, reconstructed_video_path, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## V3\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "import torch  # Assuming the model is a PyTorch model\n",
    "\n",
    "# Function for capturing live feed and saving frames to `original_temp_frames`\n",
    "def capture_live_feed(original_frames_folder, fps=30):\n",
    "    # Set up video capture for live feed (0 for the default camera)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open the camera.\")\n",
    "        return\n",
    "    \n",
    "    frame_count = 0\n",
    "    print(\"Capturing live feed... Press 'q' to quit.\")\n",
    "    \n",
    "    # Capture loop\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Display the live feed\n",
    "        cv2.imshow('Live Feed', frame)\n",
    "        \n",
    "        # Save each frame temporarily\n",
    "        frame_count += 1\n",
    "        frame_path = os.path.join(original_frames_folder, f\"frame_{frame_count}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        \n",
    "        # Quit with 'q' key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        # Wait to match the target FPS\n",
    "        time.sleep(1 / fps)\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Captured live feed frames saved to {original_frames_folder}\")\n",
    "\n",
    "# Function for loading frames, enhancing, and saving to `enhanced_temp_frames` and video\n",
    "def enhance_and_reconstruct(original_frames_folder, enhanced_frames_folder, reconstructed_video_path, model, fps=30):\n",
    "    # Set up video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    \n",
    "    # Loop to process frames in real time\n",
    "    frame_count = 1\n",
    "    video_writer = None\n",
    "    \n",
    "    print(\"Starting enhancement and reconstruction...\")\n",
    "    while True:\n",
    "        # Path of the current frame to be enhanced\n",
    "        frame_path = os.path.join(original_frames_folder, f\"frame_{frame_count}.jpg\")\n",
    "        \n",
    "        # Wait for the frame to be available in the folder\n",
    "        if not os.path.exists(frame_path):\n",
    "            time.sleep(0.05)\n",
    "            continue\n",
    "        \n",
    "        # Load the frame, enhance it, and save to enhanced folder\n",
    "        frame_pil = Image.open(frame_path).convert('RGB')\n",
    "        sr_image = model.predict(frame_pil)  # Enhance with the model\n",
    "        enhanced_frame = np.array(sr_image)\n",
    "        \n",
    "        # Save enhanced frame\n",
    "        enhanced_frame_path = os.path.join(enhanced_frames_folder, f\"frame_{frame_count}.jpg\")\n",
    "        sr_image.save(enhanced_frame_path)\n",
    "        \n",
    "        # Initialize video writer if not already set up\n",
    "        if video_writer is None:\n",
    "            height, width = enhanced_frame.shape[:2]\n",
    "            video_writer = cv2.VideoWriter(reconstructed_video_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        # Write enhanced frame to output video\n",
    "        video_writer.write(cv2.cvtColor(enhanced_frame, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        frame_count += 1\n",
    "\n",
    "    # Release resources when done\n",
    "    video_writer.release()\n",
    "    print(f\"Enhanced frames and reconstructed video saved to {enhanced_frames_folder} and {reconstructed_video_path}\")\n",
    "\n",
    "# Set up directories\n",
    "original_frames_folder = \"temp\"      # Temporary folder for original frames\n",
    "enhanced_frames_folder = \"temp_enhanced\"      # Temporary folder for enhanced frames\n",
    "reconstructed_video_path = \"output/reconstructed_video.mp4\"  # Path to save the output video\n",
    "\n",
    "# Create folders if they don't exist\n",
    "os.makedirs(original_frames_folder, exist_ok=True)\n",
    "os.makedirs(enhanced_frames_folder, exist_ok=True)\n",
    "\n",
    "# Load your pre-trained PyTorch enhancement model here\n",
    "# Example: Your PyTorch image enhancement model\n",
    "\n",
    "# Run both capture and enhancement processes in separate threads\n",
    "capture_thread = threading.Thread(target=capture_live_feed, args=(original_frames_folder,))\n",
    "enhance_thread = threading.Thread(target=enhance_and_reconstruct, args=(original_frames_folder, enhanced_frames_folder, reconstructed_video_path, model))\n",
    "\n",
    "# Start threads\n",
    "capture_thread.start()\n",
    "enhance_thread.start()\n",
    "\n",
    "# Wait for threads to complete\n",
    "capture_thread.join()\n",
    "enhance_thread.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
